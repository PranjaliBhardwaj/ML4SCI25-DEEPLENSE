{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11223557,"sourceType":"datasetVersion","datasetId":7009558}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task III  Image Super-resolution \nTrain a deep learning-based super resolution algorithm of your choice to upscale low-resolution strong lensing images using the provided high-resolution samples as ground truths. Please implement your approach in PyTorch or Keras and discuss your strategy.\n","metadata":{}},{"cell_type":"markdown","source":"This code implements a Generative Adversarial Network (GAN)-based Super-Resolution approach using PyTorch.","metadata":{}},{"cell_type":"markdown","source":"You can read [more](https://pyimagesearch.com/2022/06/06/super-resolution-generative-adversarial-networks-srgan/) here about SRGAN(Super Resolution Generative Adversiial Netwrok) ","metadata":{}},{"cell_type":"markdown","source":"**Why this approach?**\nUsing CNN and transformer based approaches could be compute-intensive, harder to train in resource-limited environments, could struggle with fine textures and perceptual quality but with GAN approach it generates sharper images with realistic textures, adversarial learning improves detail restoration. Strong lensing images contain complex patterns, and GANs help generate realistic high-frequency details missing in CNN-based approaches.","metadata":{}},{"cell_type":"code","source":"\nimport os\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.amp import GradScaler, autocast\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nimport warnings\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"data loading","metadata":{}},{"cell_type":"code","source":"\n# Increased Batch Size (64 â†’ from 32) for stable training.\n# Useing pin_memory=True and num_workers=4 for faster data loading.\n# Optimized Configuration\nconfig = {\n    'hr_path': '/kaggle/input/dataset3/Dataset/HR',\n    'lr_path': '/kaggle/input/dataset3/Dataset/LR',\n    'batch_size': 64,  \n    'lr': 2e-4,\n    'num_epochs': 12,  \n    'scale_factor': 2,\n    'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n    'save_path': './saved_models',\n    'num_workers': 4,\n    'mixed_precision': True,\n    'patience': 3,  \n    'validate_every': 2  \n}\nos.makedirs(config['save_path'], exist_ok=True)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Optimized Dataset Class\nclass StrongLensingDataset(Dataset):\n    def __init__(self, hr_dir, lr_dir):\n        self.hr_dir = hr_dir\n        self.lr_dir = lr_dir\n        \n        self.hr_files = sorted(f for f in os.listdir(hr_dir) if f.endswith('.npy'))\n        self.lr_files = sorted(f for f in os.listdir(lr_dir) if f.endswith('.npy'))\n        \n        sample_hr = np.load(os.path.join(hr_dir, self.hr_files[0]))\n        sample_lr = np.load(os.path.join(lr_dir, self.lr_files[0]))\n        \n        self.hr_shape = sample_hr.squeeze().shape\n        self.lr_shape = sample_lr.squeeze().shape\n        \n        print(f\"Dataset with HR: {self.hr_shape}, LR: {self.lr_shape}\")\n\n    def __len__(self):\n        return len(self.hr_files)\n    \n    def __getitem__(self, idx):\n        hr_img = np.load(os.path.join(self.hr_dir, self.hr_files[idx])).squeeze()\n        lr_img = np.load(os.path.join(self.lr_dir, self.lr_files[idx])).squeeze()\n        \n        hr_img = torch.from_numpy(hr_img.copy()).float().unsqueeze(0)\n        lr_img = torch.from_numpy(lr_img.copy()).float().unsqueeze(0)\n        \n        hr_img = (hr_img - hr_img.min()) / (hr_img.max() - hr_img.min())\n        lr_img = (lr_img - lr_img.min()) / (lr_img.max() - lr_img.min())\n        \n        return lr_img, hr_img\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Generator**\n<br>\n* Takes a low-resolution image as input and generates a high-resolution version.\n* Uses 4 residual blocks (instead of 6) for efficiency.\n* PReLU activation for better gradient flow.\n* PixelShuffle Upsampling for improved super-resolution performance.\n* Sigmoid activation at the final layer to normalize the output.","metadata":{}},{"cell_type":"code","source":"\n#  Generator\nclass Generator(nn.Module):\n    def __init__(self, scale_factor=2):\n        super().__init__()\n        nf = 48  # Reduced from 64\n        \n        self.initial = nn.Sequential(\n            nn.Conv2d(1, nf, 3, padding=1),\n            nn.PReLU()\n        )\n        \n        # Reduced from 6 to 4 residual blocks\n        self.res_blocks = nn.Sequential(*[\n            nn.Sequential(\n                nn.Conv2d(nf, nf, 3, padding=1),\n                nn.BatchNorm2d(nf),\n                nn.PReLU(),\n                nn.Conv2d(nf, nf, 3, padding=1),\n                nn.BatchNorm2d(nf)\n            ) for _ in range(4)\n        ])\n        \n        self.upsample = nn.Sequential(\n            nn.Conv2d(nf, nf*(scale_factor**2), 3, padding=1),\n            nn.PixelShuffle(scale_factor),\n            nn.PReLU()\n        )\n        \n        self.final = nn.Sequential(\n            nn.Conv2d(nf, 1, 3, padding=1),\n            nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        if x.dim() == 5:\n            x = x.squeeze(1)\n        x0 = self.initial(x)\n        x = self.res_blocks(x0) + x0\n        x = self.upsample(x)\n        return self.final(x)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Discriminator**\n* Distinguishes between real HR images and generated (fake) images.\n* Uses InstanceNorm for better normalization.\n* LeakyReLU activation for stable training.\n* Outputs a binary prediction indicating whether an image is real or fake.\n\n","metadata":{}},{"cell_type":"code","source":"\n\n# Discriminator\nclass Discriminator(nn.Module):\n    def __init__(self, input_size=150):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(1, 64, 4, stride=2, padding=1),\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(64, 128, 4, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.LeakyReLU(0.2),\n            \n            nn.Conv2d(128, 1, 4, stride=2, padding=1)\n        )\n    \n    def forward(self, x):\n        if x.dim() == 5:\n            x = x.squeeze(1)\n        return self.model(x)\n\n# Useing Automatic Mixed Precision (AMP) via torch.amp to reduce memory usage and speed up training.\n# Useing GradScaler to avoid underflow in gradient updates.\n\ndef train():\n    # Initialize\n    dataset = StrongLensingDataset(config['hr_path'], config['lr_path'])\n    train_size = int(0.8 * len(dataset))\n    val_size = len(dataset) - train_size\n    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size=config['batch_size'],\n        shuffle=True,\n        num_workers=config['num_workers'],\n        pin_memory=True\n    )\n    \n    val_loader = DataLoader(\n        val_dataset,\n        batch_size=config['batch_size']*2,  # Larger batches for validation\n        num_workers=config['num_workers'],\n        pin_memory=True\n    )\n    \n    generator = Generator(config['scale_factor']).to(config['device'])\n    discriminator = Discriminator(input_size=dataset.hr_shape[0]).to(config['device'])\n    \n    criterion_GAN = nn.BCEWithLogitsLoss()\n    criterion_pixel = nn.L1Loss()\n    \n    optimizer_G = optim.Adam(generator.parameters(), lr=config['lr'], betas=(0.9, 0.999))\n    optimizer_D = optim.Adam(discriminator.parameters(), lr=config['lr'], betas=(0.9, 0.999))\n    \n    scaler = GradScaler('cuda', enabled=config['mixed_precision'])\n    \n    best_psnr = 0.0\n    epochs_no_improve = 0\n    \n    for epoch in range(config['num_epochs']):\n        generator.train()\n        discriminator.train()\n        \n        for i, (lr_imgs, hr_imgs) in enumerate(train_loader):\n            lr_imgs = lr_imgs.to(config['device'], non_blocking=True)\n            hr_imgs = hr_imgs.to(config['device'], non_blocking=True)\n            \n            # Get proper target size from discriminator\n            with torch.no_grad():\n                test_output = discriminator(hr_imgs[:1])\n                target_size = test_output.shape[2:]\n            \n            valid = torch.ones(lr_imgs.size(0), 1, *target_size, device=config['device'])\n            fake = torch.zeros(lr_imgs.size(0), 1, *target_size, device=config['device'])\n            \n            # Train Generator\n            optimizer_G.zero_grad(set_to_none=True)\n            \n            with autocast('cuda', enabled=config['mixed_precision']):\n                gen_hr = generator(lr_imgs)\n                loss_pixel = criterion_pixel(gen_hr, hr_imgs)\n                pred_gen = discriminator(gen_hr)\n                loss_GAN = criterion_GAN(pred_gen, valid)\n                loss_G = loss_pixel + 0.001 * loss_GAN\n            \n            scaler.scale(loss_G).backward()\n            scaler.step(optimizer_G)\n            \n            # Train Discriminator\n            optimizer_D.zero_grad(set_to_none=True)\n            \n            with autocast('cuda', enabled=config['mixed_precision']):\n                pred_real = discriminator(hr_imgs)\n                loss_real = criterion_GAN(pred_real, valid)\n                pred_fake = discriminator(gen_hr.detach())\n                loss_fake = criterion_GAN(pred_fake, fake)\n                loss_D = (loss_real + loss_fake) / 2\n            \n            scaler.scale(loss_D).backward()\n            scaler.step(optimizer_D)\n            scaler.update()\n            \n            if i % 50 == 0:  # Reduced logging frequency\n                print(f\"[Epoch {epoch+1}/{config['num_epochs']}] [Batch {i}] \"\n                      f\"Loss_D: {loss_D.item():.4f} Loss_G: {loss_G.item():.4f}\")\n        \n        # Validation (every 'validate_every' epochs)\n        if (epoch + 1) % config['validate_every'] == 0:\n            generator.eval()\n            val_metrics = {'mse': 0.0, 'ssim': 0.0, 'psnr': 0.0}\n            \n            with torch.no_grad():\n                for lr_imgs, hr_imgs in val_loader:\n                    lr_imgs = lr_imgs.to(config['device'], non_blocking=True)\n                    hr_imgs = hr_imgs.to(config['device'], non_blocking=True)\n                    \n                    with autocast('cuda', enabled=config['mixed_precision']):\n                        fake_hr = generator(lr_imgs)\n                    \n                    fake_np = fake_hr.squeeze().cpu().numpy()\n                    real_np = hr_imgs.squeeze().cpu().numpy()\n                    \n                    val_metrics['mse'] += np.sum((fake_np - real_np) ** 2)\n                    for f, r in zip(fake_np, real_np):\n                        val_metrics['ssim'] += ssim(f, r, data_range=1.0)\n                        val_metrics['psnr'] += psnr(r, f, data_range=1.0)\n            \n            val_metrics = {k: v / val_size for k, v in val_metrics.items()}\n            \n            print(f\"\\nValidation - MSE: {val_metrics['mse']:.4f}, \"\n                  f\"SSIM: {val_metrics['ssim']:.4f}, PSNR: {val_metrics['psnr']:.4f}\\n\")\n            \n            # Early stopping check\n            if val_metrics['psnr'] > best_psnr:\n                best_psnr = val_metrics['psnr']\n                epochs_no_improve = 0\n                torch.save(generator.state_dict(), \n                          os.path.join(config['save_path'], 'best_generator.pth'))\n                print(f\"Saved model with PSNR: {best_psnr:.4f}\")\n            else:\n                epochs_no_improve += 1\n                if epochs_no_improve >= config['patience']:\n                    print(f\"Early stopping at epoch {epoch+1}\")\n                    break\n\nif __name__ == '__main__':\n    train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-04T07:43:57.053912Z","iopub.execute_input":"2025-04-04T07:43:57.054188Z","iopub.status.idle":"2025-04-04T14:49:29.779814Z","shell.execute_reply.started":"2025-04-04T07:43:57.054159Z","shell.execute_reply":"2025-04-04T14:49:29.778165Z"}},"outputs":[{"name":"stdout","text":"Dataset with HR: (150, 150), LR: (75, 75)\n[Epoch 1/12] [Batch 0] Loss_D: 0.6747 Loss_G: 0.4440\n[Epoch 1/12] [Batch 50] Loss_D: 0.6343 Loss_G: 0.0107\n[Epoch 1/12] [Batch 100] Loss_D: 0.6290 Loss_G: 0.0095\n[Epoch 2/12] [Batch 0] Loss_D: 0.5807 Loss_G: 0.0081\n[Epoch 2/12] [Batch 50] Loss_D: 0.5920 Loss_G: 0.0078\n[Epoch 2/12] [Batch 100] Loss_D: 0.5928 Loss_G: 0.0076\n\nValidation - MSE: 2.5796, SSIM: 0.9625, PSNR: 39.4999\n\nSaved model with PSNR: 39.4999\n[Epoch 3/12] [Batch 0] Loss_D: 0.5817 Loss_G: 0.0073\n[Epoch 3/12] [Batch 50] Loss_D: 0.6142 Loss_G: 0.0077\n[Epoch 3/12] [Batch 100] Loss_D: 0.5765 Loss_G: 0.0073\n[Epoch 4/12] [Batch 0] Loss_D: 0.5963 Loss_G: 0.0073\n[Epoch 4/12] [Batch 50] Loss_D: 0.5988 Loss_G: 0.0070\n[Epoch 4/12] [Batch 100] Loss_D: 0.5963 Loss_G: 0.0073\n\nValidation - MSE: 2.2574, SSIM: 0.9681, PSNR: 40.0767\n\nSaved model with PSNR: 40.0767\n[Epoch 5/12] [Batch 0] Loss_D: 0.5807 Loss_G: 0.0072\n[Epoch 5/12] [Batch 50] Loss_D: 0.5559 Loss_G: 0.0068\n[Epoch 5/12] [Batch 100] Loss_D: 0.5528 Loss_G: 0.0075\n[Epoch 6/12] [Batch 0] Loss_D: 0.5541 Loss_G: 0.0073\n[Epoch 6/12] [Batch 50] Loss_D: 0.5265 Loss_G: 0.0072\n[Epoch 6/12] [Batch 100] Loss_D: 0.5296 Loss_G: 0.0069\n\nValidation - MSE: 2.3049, SSIM: 0.9680, PSNR: 39.9918\n\n[Epoch 7/12] [Batch 0] Loss_D: 0.5356 Loss_G: 0.0071\n[Epoch 7/12] [Batch 50] Loss_D: 0.5710 Loss_G: 0.0069\n[Epoch 7/12] [Batch 100] Loss_D: 0.5723 Loss_G: 0.0073\n[Epoch 8/12] [Batch 0] Loss_D: 0.5787 Loss_G: 0.0074\n[Epoch 8/12] [Batch 50] Loss_D: 0.5459 Loss_G: 0.0074\n[Epoch 8/12] [Batch 100] Loss_D: 0.6149 Loss_G: 0.0074\n\nValidation - MSE: 1.9409, SSIM: 0.9689, PSNR: 40.7136\n\nSaved model with PSNR: 40.7136\n[Epoch 9/12] [Batch 0] Loss_D: 0.5853 Loss_G: 0.0068\n[Epoch 9/12] [Batch 50] Loss_D: 0.5776 Loss_G: 0.0071\n[Epoch 9/12] [Batch 100] Loss_D: 0.5227 Loss_G: 0.0090\n[Epoch 10/12] [Batch 0] Loss_D: 0.5365 Loss_G: 0.0074\n[Epoch 10/12] [Batch 50] Loss_D: 0.5153 Loss_G: 0.0071\n[Epoch 10/12] [Batch 100] Loss_D: 0.5228 Loss_G: 0.0072\n\nValidation - MSE: 2.1834, SSIM: 0.9655, PSNR: 40.1967\n\n[Epoch 11/12] [Batch 0] Loss_D: 0.5036 Loss_G: 0.0068\n[Epoch 11/12] [Batch 50] Loss_D: 0.5223 Loss_G: 0.0068\n[Epoch 11/12] [Batch 100] Loss_D: 0.5014 Loss_G: 0.0070\n[Epoch 12/12] [Batch 0] Loss_D: 0.5048 Loss_G: 0.0072\n[Epoch 12/12] [Batch 50] Loss_D: 0.5008 Loss_G: 0.0071\n[Epoch 12/12] [Batch 100] Loss_D: 0.4939 Loss_G: 0.0074\n\nValidation - MSE: 2.3459, SSIM: 0.9680, PSNR: 39.9210\n\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
