{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11133628,"sourceType":"datasetVersion","datasetId":6943979},{"sourceId":11133801,"sourceType":"datasetVersion","datasetId":6944104}],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Task 02 : Lens Finding\nTask: Build a model identifying lenses using PyTorch or Keras. For the training use the images in train_lenses and train_nonlenses directories, for evaluation use the images from test_lenses and test_nonlenses directories. Note that the number of non-lenses is much larger than the number of lensed galaxies. Pick the most appropriate approach and discuss your strategy.\n","metadata":{}},{"cell_type":"markdown","source":"## Breakdown to approach: \n* Handling Class Imbalance Properly, The dataset has far more non-lens images than lens images. I am using data augmentation, supporting sampling techniques, allowing for weighted loss functions.\n* Faster convergence as there is effecinet data loading.\n* Using CNN for feature extraction, using a pre trained model for fine tuning can save time and results better.\n* It also aligns with project's expectation, (Increase the number of known strong lenses. and Insight into properties of the identified lens candidates.) \n\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nimport torchvision.models as models\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport os\nfrom sklearn.metrics import roc_auc_score, roc_curve\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:49:55.947098Z","iopub.execute_input":"2025-03-23T06:49:55.947458Z","iopub.status.idle":"2025-03-23T06:50:04.630823Z","shell.execute_reply.started":"2025-03-23T06:49:55.947420Z","shell.execute_reply":"2025-03-23T06:50:04.629695Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class LensDataset(Dataset):\n    def __init__(self, lens_dir, non_lens_dir, transform=None):\n        self.lens_images = [os.path.join(lens_dir, f) for f in os.listdir(lens_dir) if f.endswith('.npy')]\n        self.non_lens_images = [os.path.join(non_lens_dir, f) for f in os.listdir(non_lens_dir) if f.endswith('.npy')]\n\n        self.images = self.lens_images + self.non_lens_images\n        self.labels = [1] * len(self.lens_images) + [0] * len(self.non_lens_images)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        img_path = self.images[idx]\n        img = np.load(img_path)  # Shape (3, 64, 64)\n        img = torch.tensor(img, dtype=torch.float32)\n\n        if self.transform:\n            img = self.transform(img)\n\n        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n        return img, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:50:04.632239Z","iopub.execute_input":"2025-03-23T06:50:04.632760Z","iopub.status.idle":"2025-03-23T06:50:04.640749Z","shell.execute_reply.started":"2025-03-23T06:50:04.632721Z","shell.execute_reply":"2025-03-23T06:50:04.639484Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Data transformations\ntransform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:50:04.641810Z","iopub.execute_input":"2025-03-23T06:50:04.642228Z","iopub.status.idle":"2025-03-23T06:50:04.664254Z","shell.execute_reply.started":"2025-03-23T06:50:04.642191Z","shell.execute_reply":"2025-03-23T06:50:04.663234Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Directories\ntrain_lens_dir = \"/kaggle/input/lens-finding-test/test_lenses\"\ntrain_non_lens_dir = \"/kaggle/input/lens-finding-test/train_nonlenses\"\ntest_lens_dir = \"/kaggle/input/lens-finding-test/test_lenses\"\ntest_non_lens_dir = \"/kaggle/input/lens-finding-test/test_nonlenses\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:52:54.606755Z","iopub.execute_input":"2025-03-23T06:52:54.607128Z","iopub.status.idle":"2025-03-23T06:52:54.611449Z","shell.execute_reply.started":"2025-03-23T06:52:54.607085Z","shell.execute_reply":"2025-03-23T06:52:54.610511Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# Create datasets and data loaders\ntrain_dataset = LensDataset(train_lens_dir, train_non_lens_dir, transform=transform)\ntest_dataset = LensDataset(test_lens_dir, test_non_lens_dir)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T06:52:56.068864Z","iopub.execute_input":"2025-03-23T06:52:56.069284Z","iopub.status.idle":"2025-03-23T06:52:56.460514Z","shell.execute_reply.started":"2025-03-23T06:52:56.069253Z","shell.execute_reply":"2025-03-23T06:52:56.459233Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"define_model_path = \"/kaggle/input/resnet/resnet18-f37072fd.pth\"\nmodel = models.resnet18()\nmodel.load_state_dict(torch.load(define_model_path, map_location=torch.device('cpu')))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:21:32.440940Z","iopub.execute_input":"2025-03-23T07:21:32.441325Z","iopub.status.idle":"2025-03-23T07:21:32.716658Z","shell.execute_reply.started":"2025-03-23T07:21:32.441295Z","shell.execute_reply":"2025-03-23T07:21:32.715673Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-17-ce3f5f0b557d>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(define_model_path, map_location=torch.device('cpu')))\n","output_type":"stream"},{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\ndefine_model_path = \"/kaggle/input/resnet/resnet18-f37072fd.pth\"\nmodel = models.resnet18()\nmodel.load_state_dict(torch.load(define_model_path, map_location=device, weights_only=True))\nmodel.fc = nn.Linear(model.fc.in_features, 1)  # Adjust for binary classification\nmodel = model.to(device)\n\n# Define loss function and optimizer\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Debug: Check if data is loading\nprint(\"Checking DataLoader...\")\nfor images, labels in train_loader:\n    print(\"Batch Shape:\", images.shape, \"Labels Shape:\", labels.shape)\n    break\n\nprint(f\"Training Samples: {len(train_loader.dataset)}\")\nprint(f\"Testing Samples: {len(test_loader.dataset)}\")\n\n# Debug: Check manual forward pass\nimages, labels = next(iter(train_loader))\nimages, labels = images.to(device), labels.to(device)\noutputs = model(images).view(-1)\nprint(\"Manual Forward Pass Output Shape:\", outputs.shape)\n\ndef train_model(model, train_loader, criterion, optimizer, num_epochs=10):\n    print(\"Starting Training...\")\n    print(f\"Training on: {device}\")\n    model.train()\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for i, (images, labels) in enumerate(train_loader):\n            images, labels = images.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(images).view(-1)\n            loss = criterion(outputs, labels.float())\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            \n            if i % 10 == 0:  # Print every 10 batches\n                print(f\"Batch {i}, Loss: {loss.item():.4f}\")\n        \n        print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {running_loss/len(train_loader):.4f}\")\n    print(\"Training Completed!\")\n\ndef evaluate_model(model, test_loader): # Evaluation using AUC and ROC curve\n    print(\"Starting Evaluation...\")\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images).view(-1)\n            probs = torch.sigmoid(outputs)\n            all_preds.extend(probs.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    auc_score = roc_auc_score(all_labels, all_preds)\n    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n\n    plt.figure()\n    plt.plot(fpr, tpr, label=f'AUC = {auc_score:.4f}')\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.legend()\n    plt.title('ROC Curve')\n    plt.show()\n\n    print(f\"AUC Score: {auc_score:.4f}\")\n\n# Run training and evaluation\ntrain_model(model, train_loader, criterion, optimizer, num_epochs=10)\nevaluate_model(model, test_loader)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T08:04:15.935732Z","iopub.execute_input":"2025-03-23T08:04:15.936140Z","iopub.status.idle":"2025-03-23T09:45:57.238421Z","shell.execute_reply.started":"2025-03-23T08:04:15.936091Z","shell.execute_reply":"2025-03-23T09:45:57.236945Z"}},"outputs":[{"name":"stdout","text":"Checking DataLoader...\nBatch Shape: torch.Size([32, 3, 64, 64]) Labels Shape: torch.Size([32])\nTraining Samples: 28870\nTesting Samples: 19650\nManual Forward Pass Output Shape: torch.Size([32])\nStarting Training...\nTraining on: cpu\nBatch 0, Loss: 0.8366\nBatch 10, Loss: 0.0288\nBatch 20, Loss: 0.3112\nBatch 30, Loss: 0.0026\nBatch 40, Loss: 0.0054\nBatch 50, Loss: 0.4523\nBatch 60, Loss: 0.0086\nBatch 70, Loss: 0.0082\nBatch 80, Loss: 0.0024\nBatch 90, Loss: 0.0021\nBatch 100, Loss: 0.1862\nBatch 110, Loss: 0.0209\nBatch 120, Loss: 0.0101\nBatch 130, Loss: 0.0065\nBatch 140, Loss: 0.0023\nBatch 150, Loss: 0.0055\nBatch 160, Loss: 0.0032\nBatch 170, Loss: 0.0060\nBatch 180, Loss: 0.2455\nBatch 190, Loss: 0.0151\nBatch 200, Loss: 0.1133\nBatch 210, Loss: 0.0170\nBatch 220, Loss: 0.0136\nBatch 230, Loss: 0.0053\nBatch 240, Loss: 0.0092\nBatch 250, Loss: 0.0032\nBatch 260, Loss: 0.0134\nBatch 270, Loss: 0.2348\nBatch 280, Loss: 0.0046\nBatch 290, Loss: 0.1211\nBatch 300, Loss: 0.0061\nBatch 310, Loss: 0.0044\nBatch 320, Loss: 0.0167\nBatch 330, Loss: 0.0080\nBatch 340, Loss: 0.0052\nBatch 350, Loss: 0.0130\nBatch 360, Loss: 0.0814\nBatch 370, Loss: 0.0838\nBatch 380, Loss: 0.0116\nBatch 390, Loss: 0.0038\nBatch 400, Loss: 0.0992\nBatch 410, Loss: 0.1258\nBatch 420, Loss: 0.0069\nBatch 430, Loss: 0.0088\nBatch 440, Loss: 0.0028\nBatch 450, Loss: 0.0039\nBatch 460, Loss: 0.0054\nBatch 470, Loss: 0.0075\nBatch 480, Loss: 0.0054\nBatch 490, Loss: 0.0035\nBatch 500, Loss: 0.1987\nBatch 510, Loss: 0.0037\nBatch 520, Loss: 0.0022\nBatch 530, Loss: 0.0081\nBatch 540, Loss: 0.0180\nBatch 550, Loss: 0.0109\nBatch 560, Loss: 0.0066\nBatch 570, Loss: 0.0050\nBatch 580, Loss: 0.0168\nBatch 590, Loss: 0.0043\nBatch 600, Loss: 0.1568\nBatch 610, Loss: 0.0024\nBatch 620, Loss: 0.0081\nBatch 630, Loss: 0.0053\nBatch 640, Loss: 0.0059\nBatch 650, Loss: 0.0054\nBatch 660, Loss: 0.0137\nBatch 670, Loss: 0.0069\nBatch 680, Loss: 0.2638\nBatch 690, Loss: 0.0049\nBatch 700, Loss: 0.0131\nBatch 710, Loss: 0.0055\nBatch 720, Loss: 0.0105\nBatch 730, Loss: 0.0079\nBatch 740, Loss: 0.0131\nBatch 750, Loss: 0.0134\nBatch 760, Loss: 0.0160\nBatch 770, Loss: 0.0054\nBatch 780, Loss: 0.0085\nBatch 790, Loss: 0.0048\nBatch 800, Loss: 0.0072\nBatch 810, Loss: 0.0036\nBatch 820, Loss: 0.0018\nBatch 830, Loss: 0.0023\nBatch 840, Loss: 0.0040\nBatch 850, Loss: 0.0011\nBatch 860, Loss: 0.0017\nBatch 870, Loss: 0.0027\nBatch 880, Loss: 0.0079\nBatch 890, Loss: 0.0203\nBatch 900, Loss: 0.1335\nEpoch 1/10, Average Loss: 0.0409\nBatch 0, Loss: 0.0277\nBatch 10, Loss: 0.0180\nBatch 20, Loss: 0.0152\nBatch 30, Loss: 0.0114\nBatch 40, Loss: 0.0104\nBatch 50, Loss: 0.0164\nBatch 60, Loss: 0.0110\nBatch 70, Loss: 0.0063\nBatch 80, Loss: 0.0033\nBatch 90, Loss: 0.0024\nBatch 100, Loss: 0.1825\nBatch 110, Loss: 0.0084\nBatch 120, Loss: 0.0076\nBatch 130, Loss: 0.0109\nBatch 140, Loss: 0.0078\nBatch 150, Loss: 0.0121\nBatch 160, Loss: 0.0056\nBatch 170, Loss: 0.0018\nBatch 180, Loss: 0.0013\nBatch 190, Loss: 0.0032\nBatch 200, Loss: 0.0052\nBatch 210, Loss: 0.1317\nBatch 220, Loss: 0.0049\nBatch 230, Loss: 0.0055\nBatch 240, Loss: 0.1559\nBatch 250, Loss: 0.0143\nBatch 260, Loss: 0.0143\nBatch 270, Loss: 0.1406\nBatch 280, Loss: 0.0074\nBatch 290, Loss: 0.0041\nBatch 300, Loss: 0.0062\nBatch 310, Loss: 0.0044\nBatch 320, Loss: 0.0025\nBatch 330, Loss: 0.0077\nBatch 340, Loss: 0.0088\nBatch 350, Loss: 0.1331\nBatch 360, Loss: 0.1245\nBatch 370, Loss: 0.0137\nBatch 380, Loss: 0.0056\nBatch 390, Loss: 0.0073\nBatch 400, Loss: 0.0042\nBatch 410, Loss: 0.0251\nBatch 420, Loss: 0.0062\nBatch 430, Loss: 0.0058\nBatch 440, Loss: 0.0072\nBatch 450, Loss: 0.0183\nBatch 460, Loss: 0.0088\nBatch 470, Loss: 0.0090\nBatch 480, Loss: 0.0074\nBatch 490, Loss: 0.0082\nBatch 500, Loss: 0.0028\nBatch 510, Loss: 0.1583\nBatch 520, Loss: 0.0048\nBatch 530, Loss: 0.1443\nBatch 540, Loss: 0.0134\nBatch 550, Loss: 0.0079\nBatch 560, Loss: 0.0075\nBatch 570, Loss: 0.0129\nBatch 580, Loss: 0.0136\nBatch 590, Loss: 0.0056\nBatch 600, Loss: 0.1336\nBatch 610, Loss: 0.0045\nBatch 620, Loss: 0.0029\nBatch 630, Loss: 0.0068\nBatch 640, Loss: 0.0024\nBatch 650, Loss: 0.0055\nBatch 660, Loss: 0.0028\nBatch 670, Loss: 0.0074\nBatch 680, Loss: 0.0059\nBatch 690, Loss: 0.2884\nBatch 700, Loss: 0.0061\nBatch 710, Loss: 0.0057\nBatch 720, Loss: 0.0055\nBatch 730, Loss: 0.2187\nBatch 740, Loss: 0.0086\nBatch 750, Loss: 0.0054\nBatch 760, Loss: 0.0024\nBatch 770, Loss: 0.1295\nBatch 780, Loss: 0.0061\nBatch 790, Loss: 0.0053\nBatch 800, Loss: 0.2008\nBatch 810, Loss: 0.0110\nBatch 820, Loss: 0.0077\nBatch 830, Loss: 0.0046\nBatch 840, Loss: 0.0034\nBatch 850, Loss: 0.2638\nBatch 860, Loss: 0.0149\nBatch 870, Loss: 0.0100\nBatch 880, Loss: 0.0078\nBatch 890, Loss: 0.0038\nBatch 900, Loss: 0.1509\nEpoch 2/10, Average Loss: 0.0372\nBatch 0, Loss: 0.0032\nBatch 10, Loss: 0.2390\nBatch 20, Loss: 0.0118\nBatch 30, Loss: 0.1443\nBatch 40, Loss: 0.4571\nBatch 50, Loss: 0.1050\nBatch 60, Loss: 0.0103\nBatch 70, Loss: 0.0068\nBatch 80, Loss: 0.0043\nBatch 90, Loss: 0.1056\nBatch 100, Loss: 0.0167\nBatch 110, Loss: 0.0084\nBatch 120, Loss: 0.0978\nBatch 130, Loss: 0.0052\nBatch 140, Loss: 0.0032\nBatch 150, Loss: 0.0046\nBatch 160, Loss: 0.1301\nBatch 170, Loss: 0.0100\nBatch 180, Loss: 0.0037\nBatch 190, Loss: 0.0034\nBatch 200, Loss: 0.0053\nBatch 210, Loss: 0.0087\nBatch 220, Loss: 0.0121\nBatch 230, Loss: 0.0101\nBatch 240, Loss: 0.0110\nBatch 250, Loss: 0.0087\nBatch 260, Loss: 0.0062\nBatch 270, Loss: 0.0995\nBatch 280, Loss: 0.0173\nBatch 290, Loss: 0.0042\nBatch 300, Loss: 0.0051\nBatch 310, Loss: 0.1021\nBatch 320, Loss: 0.0134\nBatch 330, Loss: 0.0103\nBatch 340, Loss: 0.0048\nBatch 350, Loss: 0.0012\nBatch 360, Loss: 0.0021\nBatch 370, Loss: 0.0138\nBatch 380, Loss: 0.0084\nBatch 390, Loss: 0.0016\nBatch 400, Loss: 0.0030\nBatch 410, Loss: 0.0016\nBatch 420, Loss: 0.0021\nBatch 430, Loss: 0.0030\nBatch 440, Loss: 0.0048\nBatch 450, Loss: 0.0148\nBatch 460, Loss: 0.0094\nBatch 470, Loss: 0.0069\nBatch 480, Loss: 0.1282\nBatch 490, Loss: 0.0106\nBatch 500, Loss: 0.0074\nBatch 510, Loss: 0.0027\nBatch 520, Loss: 0.0097\nBatch 530, Loss: 0.0115\nBatch 540, Loss: 0.0067\nBatch 550, Loss: 0.0036\nBatch 560, Loss: 0.0046\nBatch 570, Loss: 0.0082\nBatch 580, Loss: 0.0075\nBatch 590, Loss: 0.0880\nBatch 600, Loss: 0.0107\nBatch 610, Loss: 0.0075\nBatch 620, Loss: 0.0046\nBatch 630, Loss: 0.0055\nBatch 640, Loss: 0.0070\nBatch 650, Loss: 0.0044\nBatch 660, Loss: 0.0021\nBatch 670, Loss: 0.0082\nBatch 680, Loss: 0.0029\nBatch 690, Loss: 0.0077\nBatch 700, Loss: 0.0079\nBatch 710, Loss: 0.0074\nBatch 720, Loss: 0.1497\nBatch 730, Loss: 0.0106\nBatch 740, Loss: 0.0045\nBatch 750, Loss: 0.0023\nBatch 760, Loss: 0.0831\nBatch 770, Loss: 0.0091\nBatch 780, Loss: 0.0041\nBatch 790, Loss: 0.0024\nBatch 800, Loss: 0.0025\nBatch 810, Loss: 0.0038\nBatch 820, Loss: 0.0026\nBatch 830, Loss: 0.0064\nBatch 840, Loss: 0.0172\nBatch 850, Loss: 0.0118\nBatch 860, Loss: 0.0062\nBatch 870, Loss: 0.0050\nBatch 880, Loss: 0.0068\nBatch 890, Loss: 0.0060\nBatch 900, Loss: 0.0081\nEpoch 3/10, Average Loss: 0.0323\nBatch 0, Loss: 0.0719\nBatch 10, Loss: 0.0145\nBatch 20, Loss: 0.0102\nBatch 30, Loss: 0.0102\nBatch 40, Loss: 0.0137\nBatch 50, Loss: 0.0843\nBatch 60, Loss: 0.0039\nBatch 70, Loss: 0.0032\nBatch 80, Loss: 0.0860\nBatch 90, Loss: 0.0043\nBatch 100, Loss: 0.0038\nBatch 110, Loss: 0.0084\nBatch 120, Loss: 0.0053\nBatch 130, Loss: 0.0062\nBatch 140, Loss: 0.2876\nBatch 150, Loss: 0.0009\nBatch 160, Loss: 0.0024\nBatch 170, Loss: 0.0018\nBatch 180, Loss: 0.0087\nBatch 190, Loss: 0.0130\nBatch 200, Loss: 0.0091\nBatch 210, Loss: 0.0067\nBatch 220, Loss: 0.0038\nBatch 230, Loss: 0.0059\nBatch 240, Loss: 0.0032\nBatch 250, Loss: 0.0690\nBatch 260, Loss: 0.0118\nBatch 270, Loss: 0.0094\nBatch 280, Loss: 0.0042\nBatch 290, Loss: 0.0029\nBatch 300, Loss: 0.0030\nBatch 310, Loss: 0.0483\nBatch 320, Loss: 0.0144\nBatch 330, Loss: 0.0411\nBatch 340, Loss: 0.0068\nBatch 350, Loss: 0.0041\nBatch 360, Loss: 0.0021\nBatch 370, Loss: 0.2290\nBatch 380, Loss: 0.0091\nBatch 390, Loss: 0.0058\nBatch 400, Loss: 0.0100\nBatch 410, Loss: 0.0130\nBatch 420, Loss: 0.0134\nBatch 430, Loss: 0.1011\nBatch 440, Loss: 0.0059\nBatch 450, Loss: 0.0061\nBatch 460, Loss: 0.0837\nBatch 470, Loss: 0.0046\nBatch 480, Loss: 0.0054\nBatch 490, Loss: 0.0059\nBatch 500, Loss: 0.1208\nBatch 510, Loss: 0.0095\nBatch 520, Loss: 0.0167\nBatch 530, Loss: 0.0100\nBatch 540, Loss: 0.0054\nBatch 550, Loss: 0.0070\nBatch 560, Loss: 0.0087\nBatch 570, Loss: 0.0107\nBatch 580, Loss: 0.0169\nBatch 590, Loss: 0.0072\nBatch 600, Loss: 0.0109\nBatch 610, Loss: 0.0567\nBatch 620, Loss: 0.0052\nBatch 630, Loss: 0.0047\nBatch 640, Loss: 0.0041\nBatch 650, Loss: 0.0059\nBatch 660, Loss: 0.0074\nBatch 670, Loss: 0.0840\nBatch 680, Loss: 0.0033\nBatch 690, Loss: 0.1322\nBatch 700, Loss: 0.0055\nBatch 710, Loss: 0.1021\nBatch 720, Loss: 0.2483\nBatch 730, Loss: 0.0151\nBatch 740, Loss: 0.0103\nBatch 750, Loss: 0.0115\nBatch 760, Loss: 0.0068\nBatch 770, Loss: 0.0411\nBatch 780, Loss: 0.0141\nBatch 790, Loss: 0.0038\nBatch 800, Loss: 0.0766\nBatch 810, Loss: 0.0022\nBatch 820, Loss: 0.0021\nBatch 830, Loss: 0.0031\nBatch 840, Loss: 0.0043\nBatch 850, Loss: 0.0053\nBatch 860, Loss: 0.0038\nBatch 870, Loss: 0.0019\nBatch 880, Loss: 0.0079\nBatch 890, Loss: 0.0042\nBatch 900, Loss: 0.0016\nEpoch 4/10, Average Loss: 0.0300\nBatch 0, Loss: 0.0017\nBatch 10, Loss: 0.0026\nBatch 20, Loss: 0.0031\nBatch 30, Loss: 0.0034\nBatch 40, Loss: 0.0023\nBatch 50, Loss: 0.0080\nBatch 60, Loss: 0.0134\nBatch 70, Loss: 0.0085\nBatch 80, Loss: 0.0051\nBatch 90, Loss: 0.0046\nBatch 100, Loss: 0.0025\nBatch 110, Loss: 0.0470\nBatch 120, Loss: 0.1007\nBatch 130, Loss: 0.0081\nBatch 140, Loss: 0.0069\nBatch 150, Loss: 0.0078\nBatch 160, Loss: 0.0032\nBatch 170, Loss: 0.0035\nBatch 180, Loss: 0.0020\nBatch 190, Loss: 0.0049\nBatch 200, Loss: 0.0097\nBatch 210, Loss: 0.0077\nBatch 220, Loss: 0.0137\nBatch 230, Loss: 0.0051\nBatch 240, Loss: 0.0040\nBatch 250, Loss: 0.0075\nBatch 260, Loss: 0.0060\nBatch 270, Loss: 0.0061\nBatch 280, Loss: 0.0032\nBatch 290, Loss: 0.0025\nBatch 300, Loss: 0.0607\nBatch 310, Loss: 0.0514\nBatch 320, Loss: 0.0103\nBatch 330, Loss: 0.0580\nBatch 340, Loss: 0.1475\nBatch 350, Loss: 0.0037\nBatch 360, Loss: 0.0072\nBatch 370, Loss: 0.0065\nBatch 380, Loss: 0.0058\nBatch 390, Loss: 0.0049\nBatch 400, Loss: 0.0023\nBatch 410, Loss: 0.0114\nBatch 420, Loss: 0.0096\nBatch 430, Loss: 0.0811\nBatch 440, Loss: 0.0084\nBatch 450, Loss: 0.1760\nBatch 460, Loss: 0.0815\nBatch 470, Loss: 0.0099\nBatch 480, Loss: 0.1075\nBatch 490, Loss: 0.0409\nBatch 500, Loss: 0.1916\nBatch 510, Loss: 0.0066\nBatch 520, Loss: 0.0158\nBatch 530, Loss: 0.0087\nBatch 540, Loss: 0.0046\nBatch 550, Loss: 0.0730\nBatch 560, Loss: 0.1511\nBatch 570, Loss: 0.0084\nBatch 580, Loss: 0.0069\nBatch 590, Loss: 0.1325\nBatch 600, Loss: 0.0442\nBatch 610, Loss: 0.0098\nBatch 620, Loss: 0.0046\nBatch 630, Loss: 0.0719\nBatch 640, Loss: 0.0036\nBatch 650, Loss: 0.0084\nBatch 660, Loss: 0.0036\nBatch 670, Loss: 0.0064\nBatch 680, Loss: 0.0041\nBatch 690, Loss: 0.3206\nBatch 700, Loss: 0.0021\nBatch 710, Loss: 0.0116\nBatch 720, Loss: 0.0042\nBatch 730, Loss: 0.0148\nBatch 740, Loss: 0.0092\nBatch 750, Loss: 0.0035\nBatch 760, Loss: 0.0028\nBatch 770, Loss: 0.0030\nBatch 780, Loss: 0.0036\nBatch 790, Loss: 0.0120\nBatch 800, Loss: 0.2245\nBatch 810, Loss: 0.0061\nBatch 820, Loss: 0.0038\nBatch 830, Loss: 0.0060\nBatch 840, Loss: 0.0349\nBatch 850, Loss: 0.0079\nBatch 860, Loss: 0.0553\nBatch 870, Loss: 0.0229\nBatch 880, Loss: 0.0245\nBatch 890, Loss: 0.0886\nBatch 900, Loss: 0.0049\nEpoch 5/10, Average Loss: 0.0258\nBatch 0, Loss: 0.0058\nBatch 10, Loss: 0.0254\nBatch 20, Loss: 0.0048\nBatch 30, Loss: 0.1075\nBatch 40, Loss: 0.2813\nBatch 50, Loss: 0.0021\nBatch 60, Loss: 0.0022\nBatch 70, Loss: 0.0032\nBatch 80, Loss: 0.0097\nBatch 90, Loss: 0.0192\nBatch 100, Loss: 0.0180\nBatch 110, Loss: 0.0603\nBatch 120, Loss: 0.0104\nBatch 130, Loss: 0.0028\nBatch 140, Loss: 0.2853\nBatch 150, Loss: 0.0090\nBatch 160, Loss: 0.1681\nBatch 170, Loss: 0.0135\nBatch 180, Loss: 0.0049\nBatch 190, Loss: 0.0023\nBatch 200, Loss: 0.0034\nBatch 210, Loss: 0.0084\nBatch 220, Loss: 0.0184\nBatch 230, Loss: 0.0241\nBatch 240, Loss: 0.0305\nBatch 250, Loss: 0.0043\nBatch 260, Loss: 0.0015\nBatch 270, Loss: 0.0388\nBatch 280, Loss: 0.0099\nBatch 290, Loss: 0.0821\nBatch 300, Loss: 0.0299\nBatch 310, Loss: 0.0028\nBatch 320, Loss: 0.1607\nBatch 330, Loss: 0.0451\nBatch 340, Loss: 0.0047\nBatch 350, Loss: 0.0068\nBatch 360, Loss: 0.0119\nBatch 370, Loss: 0.0065\nBatch 380, Loss: 0.0181\nBatch 390, Loss: 0.0607\nBatch 400, Loss: 0.1748\nBatch 410, Loss: 0.0068\nBatch 420, Loss: 0.0165\nBatch 430, Loss: 0.0049\nBatch 440, Loss: 0.1672\nBatch 450, Loss: 0.0612\nBatch 460, Loss: 0.0642\nBatch 470, Loss: 0.0034\nBatch 480, Loss: 0.0096\nBatch 490, Loss: 0.0025\nBatch 500, Loss: 0.0031\nBatch 510, Loss: 0.0129\nBatch 520, Loss: 0.0441\nBatch 530, Loss: 0.0175\nBatch 540, Loss: 0.0129\nBatch 550, Loss: 0.0046\nBatch 560, Loss: 0.0025\nBatch 570, Loss: 0.0065\nBatch 580, Loss: 0.0042\nBatch 590, Loss: 0.0076\nBatch 600, Loss: 0.0055\nBatch 610, Loss: 0.0008\nBatch 620, Loss: 0.0054\nBatch 630, Loss: 0.0107\nBatch 640, Loss: 0.0124\nBatch 650, Loss: 0.0575\nBatch 660, Loss: 0.0186\nBatch 670, Loss: 0.0025\nBatch 680, Loss: 0.0012\nBatch 690, Loss: 0.0345\nBatch 700, Loss: 0.0076\nBatch 710, Loss: 0.0598\nBatch 720, Loss: 0.0053\nBatch 730, Loss: 0.0300\nBatch 740, Loss: 0.0194\nBatch 750, Loss: 0.0064\nBatch 760, Loss: 0.0016\nBatch 770, Loss: 0.0193\nBatch 780, Loss: 0.0011\nBatch 790, Loss: 0.0898\nBatch 800, Loss: 0.0332\nBatch 810, Loss: 0.0181\nBatch 820, Loss: 0.0013\nBatch 830, Loss: 0.0097\nBatch 840, Loss: 0.1043\nBatch 850, Loss: 0.0023\nBatch 860, Loss: 0.0032\nBatch 870, Loss: 0.0020\nBatch 880, Loss: 0.0128\nBatch 890, Loss: 0.0210\nBatch 900, Loss: 0.0089\nEpoch 6/10, Average Loss: 0.0235\nBatch 0, Loss: 0.0678\nBatch 10, Loss: 0.0027\nBatch 20, Loss: 0.0053\nBatch 30, Loss: 0.0103\nBatch 40, Loss: 0.0140\nBatch 50, Loss: 0.0012\nBatch 60, Loss: 0.0080\nBatch 70, Loss: 0.0281\nBatch 80, Loss: 0.0009\nBatch 90, Loss: 0.0010\nBatch 100, Loss: 0.0018\nBatch 110, Loss: 0.0039\nBatch 120, Loss: 0.0025\nBatch 130, Loss: 0.0024\nBatch 140, Loss: 0.0013\nBatch 150, Loss: 0.3828\nBatch 160, Loss: 0.0010\nBatch 170, Loss: 0.0067\nBatch 180, Loss: 0.0069\nBatch 190, Loss: 0.0032\nBatch 200, Loss: 0.0076\nBatch 210, Loss: 0.0087\nBatch 220, Loss: 0.0209\nBatch 230, Loss: 0.0293\nBatch 240, Loss: 0.0012\nBatch 250, Loss: 0.0026\nBatch 260, Loss: 0.0030\nBatch 270, Loss: 0.0368\nBatch 280, Loss: 0.0038\nBatch 290, Loss: 0.0064\nBatch 300, Loss: 0.0022\nBatch 310, Loss: 0.0032\nBatch 320, Loss: 0.0094\nBatch 330, Loss: 0.0123\nBatch 340, Loss: 0.1141\nBatch 350, Loss: 0.0092\nBatch 360, Loss: 0.0095\nBatch 370, Loss: 0.0034\nBatch 380, Loss: 0.0090\nBatch 390, Loss: 0.0040\nBatch 400, Loss: 0.0740\nBatch 410, Loss: 0.0062\nBatch 420, Loss: 0.0087\nBatch 430, Loss: 0.0401\nBatch 440, Loss: 0.0252\nBatch 450, Loss: 0.0041\nBatch 460, Loss: 0.0038\nBatch 470, Loss: 0.0044\nBatch 480, Loss: 0.0043\nBatch 490, Loss: 0.0160\nBatch 500, Loss: 0.1523\nBatch 510, Loss: 0.0029\nBatch 520, Loss: 0.0026\nBatch 530, Loss: 0.0085\nBatch 540, Loss: 0.0090\nBatch 550, Loss: 0.0121\nBatch 560, Loss: 0.0912\nBatch 570, Loss: 0.0147\nBatch 580, Loss: 0.0144\nBatch 590, Loss: 0.2272\nBatch 600, Loss: 0.0037\nBatch 610, Loss: 0.0371\nBatch 620, Loss: 0.0099\nBatch 630, Loss: 0.0033\nBatch 640, Loss: 0.0051\nBatch 650, Loss: 0.0694\nBatch 660, Loss: 0.0495\nBatch 670, Loss: 0.0103\nBatch 680, Loss: 0.0080\nBatch 690, Loss: 0.0036\nBatch 700, Loss: 0.0584\nBatch 710, Loss: 0.0175\nBatch 720, Loss: 0.0298\nBatch 730, Loss: 0.0009\nBatch 740, Loss: 0.0052\nBatch 750, Loss: 0.0099\nBatch 760, Loss: 0.0056\nBatch 770, Loss: 0.0009\nBatch 780, Loss: 0.0043\nBatch 790, Loss: 0.0028\nBatch 800, Loss: 0.0108\nBatch 810, Loss: 0.0017\nBatch 820, Loss: 0.0087\nBatch 830, Loss: 0.0487\nBatch 840, Loss: 0.1316\nBatch 850, Loss: 0.0038\nBatch 860, Loss: 0.0053\nBatch 870, Loss: 0.0539\nBatch 880, Loss: 0.0025\nBatch 890, Loss: 0.0030\nBatch 900, Loss: 0.0017\nEpoch 7/10, Average Loss: 0.0230\nBatch 0, Loss: 0.0019\nBatch 10, Loss: 0.0129\nBatch 20, Loss: 0.0472\nBatch 30, Loss: 0.0038\nBatch 40, Loss: 0.0271\nBatch 50, Loss: 0.0089\nBatch 60, Loss: 0.0070\nBatch 70, Loss: 0.0034\nBatch 80, Loss: 0.0028\nBatch 90, Loss: 0.0046\nBatch 100, Loss: 0.2634\nBatch 110, Loss: 0.0007\nBatch 120, Loss: 0.0006\nBatch 130, Loss: 0.0024\nBatch 140, Loss: 0.0498\nBatch 150, Loss: 0.0023\nBatch 160, Loss: 0.1512\nBatch 170, Loss: 0.0071\nBatch 180, Loss: 0.0079\nBatch 190, Loss: 0.0135\nBatch 200, Loss: 0.0014\nBatch 210, Loss: 0.0029\nBatch 220, Loss: 0.0042\nBatch 230, Loss: 0.0191\nBatch 240, Loss: 0.0240\nBatch 250, Loss: 0.0041\nBatch 260, Loss: 0.0019\nBatch 270, Loss: 0.0028\nBatch 280, Loss: 0.0039\nBatch 290, Loss: 0.0018\nBatch 300, Loss: 0.0799\nBatch 310, Loss: 0.0016\nBatch 320, Loss: 0.0012\nBatch 330, Loss: 0.0013\nBatch 340, Loss: 0.0005\nBatch 350, Loss: 0.0090\nBatch 360, Loss: 0.0022\nBatch 370, Loss: 0.0029\nBatch 380, Loss: 0.0010\nBatch 390, Loss: 0.0031\nBatch 400, Loss: 0.0141\nBatch 410, Loss: 0.0042\nBatch 420, Loss: 0.0796\nBatch 430, Loss: 0.0043\nBatch 440, Loss: 0.0322\nBatch 450, Loss: 0.0305\nBatch 460, Loss: 0.0095\nBatch 470, Loss: 0.0111\nBatch 480, Loss: 0.0054\nBatch 490, Loss: 0.0052\nBatch 500, Loss: 0.0027\nBatch 510, Loss: 0.0016\nBatch 520, Loss: 0.0159\nBatch 530, Loss: 0.0015\nBatch 540, Loss: 0.0289\nBatch 550, Loss: 0.1178\nBatch 560, Loss: 0.0259\nBatch 570, Loss: 0.0625\nBatch 580, Loss: 0.0200\nBatch 590, Loss: 0.0131\nBatch 600, Loss: 0.1341\nBatch 610, Loss: 0.0008\nBatch 620, Loss: 0.0110\nBatch 630, Loss: 0.0216\nBatch 640, Loss: 0.0029\nBatch 650, Loss: 0.0096\nBatch 660, Loss: 0.0068\nBatch 670, Loss: 0.0048\nBatch 680, Loss: 0.0016\nBatch 690, Loss: 0.2262\nBatch 700, Loss: 0.0116\nBatch 710, Loss: 0.0019\nBatch 720, Loss: 0.0097\nBatch 730, Loss: 0.0006\nBatch 740, Loss: 0.0004\nBatch 750, Loss: 0.0127\nBatch 760, Loss: 0.0022\nBatch 770, Loss: 0.0007\nBatch 780, Loss: 0.0038\nBatch 790, Loss: 0.0070\nBatch 800, Loss: 0.1151\nBatch 810, Loss: 0.0076\nBatch 820, Loss: 0.0018\nBatch 830, Loss: 0.0014\nBatch 840, Loss: 0.0108\nBatch 850, Loss: 0.0019\nBatch 860, Loss: 0.0136\nBatch 870, Loss: 0.0019\nBatch 880, Loss: 0.0158\nBatch 890, Loss: 0.0106\nBatch 900, Loss: 0.0037\nEpoch 8/10, Average Loss: 0.0221\nBatch 0, Loss: 0.0028\nBatch 10, Loss: 0.0169\nBatch 20, Loss: 0.0053\nBatch 30, Loss: 0.0081\nBatch 40, Loss: 0.0712\nBatch 50, Loss: 0.0151\nBatch 60, Loss: 0.1472\nBatch 70, Loss: 0.0067\nBatch 80, Loss: 0.0152\nBatch 90, Loss: 0.0068\nBatch 100, Loss: 0.0590\nBatch 110, Loss: 0.0042\nBatch 120, Loss: 0.0395\nBatch 130, Loss: 0.0018\nBatch 140, Loss: 0.0283\nBatch 150, Loss: 0.0123\nBatch 160, Loss: 0.0011\nBatch 170, Loss: 0.0232\nBatch 180, Loss: 0.0035\nBatch 190, Loss: 0.0029\nBatch 200, Loss: 0.0052\nBatch 210, Loss: 0.0071\nBatch 220, Loss: 0.0012\nBatch 230, Loss: 0.0074\nBatch 240, Loss: 0.0232\nBatch 250, Loss: 0.0031\nBatch 260, Loss: 0.0029\nBatch 270, Loss: 0.0075\nBatch 280, Loss: 0.0074\nBatch 290, Loss: 0.0067\nBatch 300, Loss: 0.0053\nBatch 310, Loss: 0.0058\nBatch 320, Loss: 0.0018\nBatch 330, Loss: 0.0092\nBatch 340, Loss: 0.0062\nBatch 350, Loss: 0.0089\nBatch 360, Loss: 0.0109\nBatch 370, Loss: 0.0071\nBatch 380, Loss: 0.0010\nBatch 390, Loss: 0.0067\nBatch 400, Loss: 0.0059\nBatch 410, Loss: 0.0084\nBatch 420, Loss: 0.0023\nBatch 430, Loss: 0.0260\nBatch 440, Loss: 0.0155\nBatch 450, Loss: 0.0567\nBatch 460, Loss: 0.0009\nBatch 470, Loss: 0.0019\nBatch 480, Loss: 0.0537\nBatch 490, Loss: 0.0058\nBatch 500, Loss: 0.0010\nBatch 510, Loss: 0.0026\nBatch 520, Loss: 0.0028\nBatch 530, Loss: 0.0029\nBatch 540, Loss: 0.0298\nBatch 550, Loss: 0.0244\nBatch 560, Loss: 0.0064\nBatch 570, Loss: 0.0597\nBatch 580, Loss: 0.0045\nBatch 590, Loss: 0.0046\nBatch 600, Loss: 0.0025\nBatch 610, Loss: 0.0064\nBatch 620, Loss: 0.1140\nBatch 630, Loss: 0.0150\nBatch 640, Loss: 0.0025\nBatch 650, Loss: 0.0018\nBatch 660, Loss: 0.0020\nBatch 670, Loss: 0.0139\nBatch 680, Loss: 0.0019\nBatch 690, Loss: 0.0008\nBatch 700, Loss: 0.0024\nBatch 710, Loss: 0.0036\nBatch 720, Loss: 0.0419\nBatch 730, Loss: 0.0088\nBatch 740, Loss: 0.0528\nBatch 750, Loss: 0.0020\nBatch 760, Loss: 0.0100\nBatch 770, Loss: 0.0046\nBatch 780, Loss: 0.0071\nBatch 790, Loss: 0.0047\nBatch 800, Loss: 0.0073\nBatch 810, Loss: 0.0022\nBatch 820, Loss: 0.4599\nBatch 830, Loss: 0.0076\nBatch 840, Loss: 0.0027\nBatch 850, Loss: 0.0007\nBatch 860, Loss: 0.0011\nBatch 870, Loss: 0.0010\nBatch 880, Loss: 0.0036\nBatch 890, Loss: 0.0041\nBatch 900, Loss: 0.0153\nEpoch 9/10, Average Loss: 0.0243\nBatch 0, Loss: 0.0196\nBatch 10, Loss: 0.0087\nBatch 20, Loss: 0.0045\nBatch 30, Loss: 0.0064\nBatch 40, Loss: 0.0039\nBatch 50, Loss: 0.0032\nBatch 60, Loss: 0.1489\nBatch 70, Loss: 0.0011\nBatch 80, Loss: 0.0155\nBatch 90, Loss: 0.0111\nBatch 100, Loss: 0.0092\nBatch 110, Loss: 0.0067\nBatch 120, Loss: 0.0008\nBatch 130, Loss: 0.0522\nBatch 140, Loss: 0.0060\nBatch 150, Loss: 0.0134\nBatch 160, Loss: 0.0080\nBatch 170, Loss: 0.0077\nBatch 180, Loss: 0.0078\nBatch 190, Loss: 0.0736\nBatch 200, Loss: 0.0015\nBatch 210, Loss: 0.0008\nBatch 220, Loss: 0.0916\nBatch 230, Loss: 0.0090\nBatch 240, Loss: 0.0089\nBatch 250, Loss: 0.0052\nBatch 260, Loss: 0.0016\nBatch 270, Loss: 0.2931\nBatch 280, Loss: 0.1201\nBatch 290, Loss: 0.0204\nBatch 300, Loss: 0.0289\nBatch 310, Loss: 0.0054\nBatch 320, Loss: 0.0243\nBatch 330, Loss: 0.1238\nBatch 340, Loss: 0.0441\nBatch 350, Loss: 0.0922\nBatch 360, Loss: 0.0340\nBatch 370, Loss: 0.1463\nBatch 380, Loss: 0.0529\nBatch 390, Loss: 0.0012\nBatch 400, Loss: 0.0023\nBatch 410, Loss: 0.0041\nBatch 420, Loss: 0.0019\nBatch 430, Loss: 0.0040\nBatch 440, Loss: 0.0017\nBatch 450, Loss: 0.0031\nBatch 460, Loss: 0.1473\nBatch 470, Loss: 0.0085\nBatch 480, Loss: 0.0753\nBatch 490, Loss: 0.0228\nBatch 500, Loss: 0.0163\nBatch 510, Loss: 0.0082\nBatch 520, Loss: 0.0050\nBatch 530, Loss: 0.0015\nBatch 540, Loss: 0.0017\nBatch 550, Loss: 0.0040\nBatch 560, Loss: 0.0115\nBatch 570, Loss: 0.0016\nBatch 580, Loss: 0.0949\nBatch 590, Loss: 0.0011\nBatch 600, Loss: 0.0049\nBatch 610, Loss: 0.0011\nBatch 620, Loss: 0.0023\nBatch 630, Loss: 0.0046\nBatch 640, Loss: 0.0094\nBatch 650, Loss: 0.0321\nBatch 660, Loss: 0.0295\nBatch 670, Loss: 0.0023\nBatch 680, Loss: 0.0008\nBatch 690, Loss: 0.0013\nBatch 700, Loss: 0.0027\nBatch 710, Loss: 0.0045\nBatch 720, Loss: 0.0139\nBatch 730, Loss: 0.0034\nBatch 740, Loss: 0.0027\nBatch 750, Loss: 0.0029\nBatch 760, Loss: 0.0625\nBatch 770, Loss: 0.0253\nBatch 780, Loss: 0.0266\nBatch 790, Loss: 0.0100\nBatch 800, Loss: 0.0824\nBatch 810, Loss: 0.0040\nBatch 820, Loss: 0.0052\nBatch 830, Loss: 0.0016\nBatch 840, Loss: 0.1005\nBatch 850, Loss: 0.0064\nBatch 860, Loss: 0.0049\nBatch 870, Loss: 0.0041\nBatch 880, Loss: 0.0144\nBatch 890, Loss: 0.0238\nBatch 900, Loss: 0.0030\nEpoch 10/10, Average Loss: 0.0235\nTraining Completed!\nStarting Evaluation...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}},{"name":"stdout","text":"AUC Score: 0.9545\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T07:28:14.415055Z","iopub.execute_input":"2025-03-23T07:28:14.415452Z","iopub.status.idle":"2025-03-23T07:28:14.425508Z","shell.execute_reply.started":"2025-03-23T07:28:14.415412Z","shell.execute_reply":"2025-03-23T07:28:14.424341Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}
